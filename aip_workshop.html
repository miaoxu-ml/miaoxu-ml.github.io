
<!-- saved from url=(0039)http://www.ms.k.u-tokyo.ac.jp/TDLW2018/ -->
<html slick-uniqueid="3" class="gr__ms_k_u-tokyo_ac_jp"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta http-equiv="Content-Language" content="en-us">

<title>The ACML2019 RIKEN AIP workshop</title>
<link rel="stylesheet" type="text/css" href="base.css">
<style type="text/css">
.auto-style1 {
	text-align: center;
}
</style>
</head>

<body data-gr-c-s-loaded="true">
<p class="auto-style1">
<!--<img alt="" height="200" src="img_center_pi_170516.jpg" width="608"></p>
&nbsp;<hr>-->

<h1>The <a href="http://www.acml-conf.org/2019/">ACML2019</a> RIKEN AIP Workshop @ Nagoya, Japan</h1>

<hr>

<!-- Introduction Section -->
    <section id="introduction">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 text-center">
					<h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
			</div>
			<div class="row text-justify">
				<div class="col-md-12">
					<p class="large text-muted">The <a href="https://aip.riken.jp/">Center for Advanced Intelligence Project (AIP), RIKEN</a> was founded in 2016 as a research center for the MEXT-AIP Project. We have fully started our research activities in 2017, mainly in our newly opened Nihonbashi Office.<br />
					</p>
					<p class="large text-muted">In the Center for AIP, we set up three research groups:
<ul>
<li>Generic Technology Research Group</li>
<li>Goal-Oriented Technology Research Group</li>
<li>Artificial Intelligence in Society Research Group</li>
</ul>Together with various companies, universities, research institutes and projects, we are tackling the following five activities: development of fundamental technology, acceleration of scientific research, the solution to societal problems, analysis of ethical, legal and social issues of AI, development of AI researchers and data scientists. 
 <br />
					</p>
					<p class="large text-muted">This RIKEN AIP Workshop@ACML19 aims at introducing the forefront machine learning researches conducted at RIKEN AIP to ACML participants, and incurring fruitful discussions between researchers inside and outside of AIP about existing key progress and promising new directions. Topics of this workshop cover a variety of theoretical and applied researches, including deep learning, reinforcement learning, weakly-supervised learning, Bayesian optimization, AI for social good, AI for disaster prevention. Our workshop invites leading researchers from all three research groups and also hosts poster presenters with a wide range of perspectives and interests.<br />
					</p>
				</div>
			</div>
		</div>
</section>

<hr>
<!-- Program Section -->
    <section id="program" class="bg-mid-gray">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 text-center">
					<h2 class="section-heading">Schedule</h2>
					<h3 class="section-subheading text-muted"><a href="https://www.winc-aichi.jp/">WINC AICHI</a>, Nagoya, Japan <br />
					10:00 am - 12:30 am (Morning Session),  16:00 pm - 18:00 pm (Afternoon Session)<br />
					Nov. 17th, 2019<br />
					</h3>
				</div>
			</div>
			<div id="schedule">
				<div class="container w">
					<h3>Morning Session</h3>
					<br />
					<div class="row centered">
						<table border="2" cellpadding="2" cellspacing="2" class="table table-striped">
							<tr>
								<td>10:00 - 10:30 </td>
								<td>Opening Remarks and Invited Talk: <br>Prof. Masashi Sugiyama <br>Introduction of RIKEN Center for Advanced Intelligence Project</td>
							</tr>
							<tr>
								<td>10:30 - 11:00 </td>
								<td>Invited Talk: <br>Prof. Naonori Ueda <br>Simulation-based Machine Learning for Earthquake Ground Motion Prediction</td>
							</tr>
							<tr>
								<td>11:00 - 11:30 </td>
								<td>Invited Talk: <br>Prof. Taiji Suzuki <br>TBA</td>
							</tr>
							<tr>
								<td>11:30 - 12:00 </td>
								<td>Invited Talk: <br>Dr. Pierre Alquier <br>MMD-Bayes: Robust Bayesian Estimation via Maximum Mean Discrepancy</td>
							</tr>
							<tr>
								<td>12:00 - 12:30</td>
								<td>Invited Talk: <br>Dr. Hiromi Arai <br>TBA</td>
							</tr>
													</table>
					</div>
					<h3>Afternoon Session</h3>
					<br />
					<div class="row centered">
						<table border="2" cellpadding="2" cellspacing="2" class="table table-striped">
							<tr>
								<td>16:00 - 18:00</td>
								<td>Poster presentations (see details <a href="#anchor-name">here</a>)</td>
                             <!-- <td>  </td> -->
                            </tr>
													</table>
					</div>
					<div class="col-lg-1 text-left">
						&nbsp; </div>
				</div>
			</div>
		</div>
</section>

<hr>

    <!-- Keynote Section -->

    <section id="keynote">
		<div class="container">
			<div class="row text-justify">
				<div class="col-lg-12 text-center">
					<h2 class="section-heading">Invited Speakers</h2>
				</div>
			</div>
			<div class="row">
				<div class="col-sm-4">
					<div class="team-member">
						<!--<img class="img-responsive img-circle" height="150" src="member_Masashi-Sugiyama.jpg" width="150" />-->
						<a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">
						<h3>Masashi Sugiyama</h3>
						</a>
						<p class="text-muted">Director/Professor<br />
						RIKEN AIP/University of Tokyo</p>
					</div>
				</div>
				<div class="col-sm-8 text-left">
					<h4>Title: Introduction of RIKEN Center for Advanced Intelligence Project</h4>
					<div class="container, col-sm-12 text-left">
				</div>
			</div>
			<p>
					<p>

			<div class="row">
				<div class="col-sm-4">
					<div class="team-member">
						<!--<img class="img-responsive img-circle" height="150" src="naonori_ueda.jpg" width="120" />-->
						<a href="http://www.kecl.ntt.co.jp/as/members/ueda/index.html">
						<h3>Naonori Ueda</h3>
						</a>
						<p class="text-muted">Deputy Director<br />
						RIKEN AIP</p>
					</div>
				</div>
				<div class="col-sm-8 text-left">
					<h4>Title: Simulation-based Machine Learning for Earthquake Ground Motion Prediction </h4>
					<div class="container, col-sm-12 text-left">
						<a class="btn btn-info" data-target="#suchi" data-toggle="collapse" type="button">
						Abstract: </a>
						<div id="suchi" class="collapse , text-muted">
							In recent years, natural disasters such as a major earthquake and the accompanying big tsunami that cause enormous damage occur. It takes a huge amount of time and cost to restore a social system that suffered greatly every time. In our research team, we aim to research and develop artificial intelligence technologies that enable to reduce the damage as much as possible, restore the social system once damaged efficiently and effectively, and resume social and economic activities promptly. In this talk, I introduce our new AI approach, fusion of AI and high performance computing (HPC), for earthquake ground motion prediction. </div>
					</div>
				</div>
			</div>
					<p>
		<p>

			<div class="row">
				<div class="col-sm-4">
					<div class="team-member">
						<!--<img class="img-responsive img-circle" height="150" src="suzuki.jpg" width="150" />-->
						<a href="http://ibis.t.u-tokyo.ac.jp/suzuki/">
						<h3>Taiji Suzuki</h3>
						</a>
						<p class="text-muted">Team Leader/Associate Professor<br />
						RIKEN AIP/University of Tokyo</p>
					</div>
				</div>
				<div class="col-sm-8 text-left">
					<h4>Title: Coming soon </h4>
					<div class="container, col-sm-12 text-left">
						<a class="btn btn-info" data-target="#yanliu" data-toggle="collapse" type="button">
						Abstract: </a>
						<div id="yanliu" class="collapse , text-muted">
							Coming soon </div>
					</div>
				</div>
			</div>
					<p>
		<p>

			<div class="row">
				<div class="col-sm-4">
					<div class="team-member">
						<!--<img class="img-responsive img-circle" height="150" src="rotterdam18-7.jpg" width="161">-->
						<a href="http://alquier.ensae.net/">
						<h3>Pierre Alquier</h3>
						</a>
						<p class="text-muted">Senior Research Scientist<br />
						RIKEN AIP</p>
					</div>
				</div>
				<div class="col-sm-8 text-left">
					<h4>Title: MMD-Bayes: Robust Bayesian Estimation via Maximum Mean Discrepancy</h4>
					<div class="container, col-sm-12 text-left">
						<a class="btn btn-info" data-target="#edo" data-toggle="collapse" type="button">
						Abstract: </a>
						<div id="edo" class="collapse , text-muted">
							In some misspecified settings, the posterior distribution in Bayesian statistics may lead to inconsistent estimates. To fix this issue, it has been suggested to replace the likelihood by a pseudo-likelihood, that is the exponential of a loss function enjoying suitable robustness properties. Inspired by the recent work of Briol et al. (2019), we build a pseudo-likelihood based on the Maximum Mean Discrepancy, defined via an embedding of probability distributions into a reproducing kernel Hilbert space. We show that the MMD-Bayes posterior is consistent and robust to model misspecification. As the posterior obtained in this way might be untractable, we also prove that reasonable variational approximations of this posterior enjoy the same properties. We provide details on a stochastic gradient algorithm to compute these variational approximations. Numerical simulations indeed suggest that our estimator is more robust to misspecification than the ones based on the likelihood.</div>
					</div>
				</div>
			</div>
		</div>
		<p>
		<p>
		<div class="row">
				<div class="col-sm-4">
					<div class="team-member">
						<!--<img class="img-responsive img-circle" height="150" src="" width="161" />-->
						<a href="https://sites.google.com/site/hrmarai1/">
						<h3>Hiromi Arai</h3>
						</a>
						<p class="text-muted">Research Scientist<br />
						RIKEN AIP</p>
					</div>
				</div>
				<div class="col-sm-8 text-left">
					<h4>Title: Coming soon</h4>
					<div class="container, col-sm-12 text-left">
						<a class="btn btn-info" data-target="#edo" data-toggle="collapse" type="button">
						Abstract</a>
						<div id="edo" class="collapse , text-muted">
							Coming soon</div>
					</div>
				</div>
			</div>
		</div>

</section>
<hr>
<!-- Papers -->
    <section id="papers" class="bg-mid-gray">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 text-center">
					<h2 class="section-heading">Posters</h2>
				</div>
			</div>
					<p id="anchor-name">Detailed information for posters: </p>
					<div class="row centered">
						<table border="2" cellpadding="2" cellspacing="2" class="table table-striped">
							<tr>
								<td>Poster ID</td>
								<td>Poster Information (16:00-18:00, Nov.17th)</td>
							</tr>
							<tr>
								<td>Sun19</td>
								<td><B>Title: </B> Advancing Multi-Task Learning for Text Classification <br><br>
								<B>Abstract:</B>
								Text classification is one of the building blocks of natural language processing. Neural models have shown promising opportunities to address the challenges of this task; however, finding general features to handle various textual domains and detecting tacit dimensions of the lexical, syntactic, and semantic structure of the data challenges the accuracy of such systems. Multi-task learning is an effective technic to improve the performance of a single task with the help of other relevant tasks. It provides an effective way to combine the knowledge acquired from different sources, to improve the performance of the system on any of the existing or unseen tasks. In this study, we employ multi-task earning for text classification to benefit from its advantages, including cross-noise cancellation, training speed-up, and transfer learning. We also proposed different architectures and loss functions to separate task-specific and shared features, leverage unlabeled data to boost system performance, and distilling core features shared between different domain for text classification.<br>
								<br><B>Presented by </B>Dr. Kourosh Meshgi</td>
							</tr>
							<tr>
								<td>Sun20</td>
								<td><B>Title: </B> 3D Immersive Situation Creation Using Natural Language Description <br><br>
								<B>Abstract:</B>
								We developed an intelligent situation creation system that enables the users to create an immersive virtual world from textual input. This system converts the user's textual descriptions into a 3D situation, character and object arrangement, characters' verbal and non-verbal behaviors, characters' mental process and feelings, camera perspective including point-of-view or camera angle, and the narration of the situation. The 3D environment can be explored with Virtual Reality headsets, desktop application or web browser, and is useful to collect situational data of human interactions to be used in various applications ranging from serious games, inter-cultural research, vocational and experiential learning, and reminiscence therapy. The naturalness of the character's actions in this system is of great importance. To create human-like non-verbals, we proposed AnimGAN to generate novel realistic gestures, postures, and actions for agents from an existing database of motion capture data. Furthermore, to amend the potential shortcomings of character animation database and allowing non-expert users to create their desired 3D character animations, we proposed another GAN-based text-to-animation system that converts the user descriptions to 3D animations by suggesting a set of videos closely related to the user query, and generating 3D actions from the user-selected video.
								<br><br><B>Presented by </B>Dr. Maryam Sadat Mirzaei</td>
							</tr>
							<tr>
								<td>Sun21</td>
								<td><B>Title: </B> Learning from only Unlabeled Data via Empirical Risk Minimization <br><br>
								<B>Abstract:</B>
								We consider the weakly-supervised learning problem of training arbitrary (from linear to deep) binary classifiers from only unlabeled (U) data by empirical risk minimization (ERM). We prove that it is possible given two sets of U data with different class priors, and then propose an unbiased risk estimator and analyze the consistency. Further, we improve it by a generalized consistent risk correction technique to mitigate the overfitting problem when flexible models are used and prove consistency for both the proposed corrected risk estimators and the resulting empirical risk minimizers for a family of consistent correction functions for the first time. Experiments demonstrate the superiority of our proposed methods.
								<br><br><B>Presented by </B>Ms. Nan Lu</td>
							</tr>
							<tr>
								<td>Sun22</td>
								<td><B>Title: </B> Encoder-Decoder Approach for Signals: wave2wave <br><br>
								<B>Abstract:</B>
								The understanding of sensor data has been greatly improved by advanced deep learning methods with big data. However, available sensor data in the real world are still limited, which is called the opportunistic sensor problem. This paper proposes a new variant of neural machine translation {\it seq2seq} to deal with continuous signal waves by introducing the {\it window-based (inverse-) representation} to adaptively represent partial shapes of waves and   the {\it  iterative back-translation model} for high-dimensional data. Experimental results are shown for two real-life data: earthquake and activity translation. The performance improvements of one-dimensional data were about 46% in test loss and that of high-dimensional data was about 1625% in perplexity with regard to the original seq2seq.
								<br><br><B>Presented by </B>Dr. Tsuyoshi Okita</td>
							</tr>
							<tr>
								<td>Sun23</td>
								<td><B>Title: </B> Non-Local Meets Global: An Integrated Paradigm for Hyperspectral Denoising <br><br>
								<B>Abstract:</B>
								Non-local low-rank tensor approximation has been developed as a state-of-the-art method for hyperspectral image (HSI) denoising. Unfortunately, while their denoising performance benefits little from more spectral bands, the running time of these methods significantly increases. In this paper, we claim that the HSI lies in a global spectral low-rank subspace, and the spectral subspaces of each full band patch groups should lie in this global low-rank subspace. This motivates us to propose a unified spatial-spectral paradigm for HSI denoising. As the new model is hard to optimize, An efficient algorithm motivated by alternating minimization is developed. This is done by first learning a low-dimensional orthogonal basis and the related reduced image from the noisy HSI. Then, the non-local low-rank denoising and iterative regularization are developed to refine the reduced image and orthogonal basis, respectively. Finally, the experiments on synthetic and both real datasets demonstrate the superiority against the state-of-the-art HSI denoising methods.
								<br><br><B>Presented by </B>Dr. Wei He</td>
							</tr>
							<tr>
								<td>Sun24</td>
								<td><B>Title: </B> Safe Grid Search with Optimal Complexity <br><br>
								<B>Abstract:</B>
								Popular machine learning estimators involve regularization parameters that can be challenging to tune, and standard strategies rely on grid search for this task. In this paper, we revisit the techniques of approximating the regularization  path up to predefined tolerance $\epsilon$ in a unified framework and show that its complexity is $O(1/\sqrt[d]{\epsilon})$ for uniformly convex loss of order $d \geq 2$ and $O(1/\sqrt{\epsilon})$ for Generalized Self-Concordant functions. This framework encompasses least-squares but also logistic regression, a case that as far as we know was not handled as precisely in previous works. We leverage our technique to provide refined bounds on the validation error as well as a practical algorithm for hyperparameter tuning. The latter has global convergence guarantee when targeting a prescribed accuracy on the validation set. Last but not least, our approach helps relieving the practitioner from the (often neglected) task of selecting a stopping criterion when optimizing over the training set: our method automatically calibrates this criterion based on the targeted accuracy on the validation set.
								<br><br><B>Presented by </B>Dr. Eugene Ndiaye</td>
							</tr>
							<tr>
								<td>Sun25</td>
								<td><B>Title: </B> Direction Matters: On Influence-Preserving Graph Summarization <br><br>
								<B>Abstract:</B>
								Summarizing large-scaled directed graphs into small-scale representations is a useful but less studied problem setting. Conventional clustering approaches, which based on "Min-Cut"-style criteria, compress both the vertices and edges of the graph into the communities, that lead to a loss of directed edge information. On the other hand, compressing the vertices while preserving the directed edge information provides a way to learn the small-scale representation of a directed graph. The reconstruction error, which measures the edge information preserved by the summarized graph, can be used to learn such representation. Compared to the original graphs, the summarized graphs are easier to analyze and are capable of extracting group-level features which is useful for efficient interventions of population behavior. In this paper, we present a model, based on minimizing reconstruction error with non-negative constraints, which relates to a "Max-Cut" criterion that simultaneously identifies the compressed nodes and the directed compressed relations between these nodes. A multiplicative update algorithm with column-wise normalization is proposed. We further provide theoretical results on the identifiability of the model and on the convergence of the proposed algorithms. Experiments are conducted to demonstrate the accuracy and robustness of the proposed method.
								<br><br><B>Presented by </B>Mr. Wenkai Xu</td>
							</tr>
							<tr>
								<td>Sun26</td>
								<td><B>Title: </B> Deep Multimodal Multilinear Fusion with High-order Polynomial Pooling <br><br>
								<B>Abstract:</B>
								Tensor-based multimodal fusion techniques have exhibited great predictive performance. Despite of being compact, the existing approaches only consider bilinear or trilinear pooling, which fails to unleash the complete expressive power of multilinear fusion with restricted orders of interactions. More importantly, they simply fuse features all at once in a global manner. Thus, the complex local intercorrelations cannot be modelled, leading to significant deterioration of the prediction. In this work, we start by proposing a high-order polynomial tensor pooling (PTP) unit that can fuse locally mixed temporal-modality features. Using PTP as a building block, we further establish a hierarchical architecture to recursively integrate local correlations into global ones. Such architecture brings dual benefits: 1) complicated local interactions can be grasped at a much finer granularity, and the dominant local correlations can be efficiently transmitted to the global scale. 2) an exponential growth of the expressivity capacity can be achieved by stacking PTPs into multiple layers, shown by the equivalence to a very deep convolutional arithmetic circuit. Various experiments demonstrate its state-of-the-art performance.
								<br><br><B>Presented by </B>Dr. Qibin Zhao</td>
							</tr>
							<tr>
								<td>Sun27</td>
								<td><B>Title: </B> Approximate Inference Turns Deep Networks into Gaussian Processes <br><br>
								<B>Abstract:</B>
								Deep neural networks (DNN) and Gaussian processes (GP) are two powerful models with several theoretical connections relating them, but the relationship between their training methods is not well understood. In this paper, we show that certain Gaussian posterior approximations for Bayesian DNNs are equivalent to GP posteriors. As a result, we can obtain a GP kernel and a nonlinear feature map simply by training the DNN. Surprisingly, the resulting kernel is the neural tangent kernel which has desirable theoretical properties for infinitely-wide DNNs. We show feature maps obtained on real datasets and demonstrate the use of the GP marginal likelihood to tune hyperparameters of DNNs. Our work aims to facilitate further research on combining DNNs and GPs in practical settings.
								<br><br><B>Presented by </B>Mr. Alex Immer</td>
							</tr>
							<tr>
								<td>Sun28</td>
								<td><B>Title: </B> Practical Deep Learning with Bayesian Principles <br><br>
								<B>Abstract:</B>
								Bayesian methods promise to fix many shortcomings of deep learning, but they are impractical and rarely match the performance of standard methods, let alone improve them. In this paper, we demonstrate practical training of deep networks with natural-gradient variational inference. By applying techniques such as batch normalisation, data augmentation, and distributed training, we achieve similar performance in about the same number of epochs as the Adam optimiser, even on large datasets such as ImageNet. Importantly, the benefits of Bayesian principles are preserved: predictive probabilities are well-calibrated, uncertainties on out-of-distribution data are improved, and continual-learning performance is boosted. This work enables practical deep learning while preserving benefits of Bayesian principles. A PyTorch implementation is available as a plug-and-play optimiser.
								<br><br><B>Presented by </B>Mr. Maciej Korzepa</td>
							</tr>
							<tr>
								<td>Sun29</td>
								<td><B>Title: </B> Faster AutoAugment: Learning Augmentation Strategies using Backpropagation <br><br>
								<B>Abstract:</B>
								Data augmentation methods are heuristics essential to prevent overfitting and to boost the performance of deep neural networks, especially in image recognition tasks. Recently, several studies show that augmentation strategies found by search algorithms outperform hand-made strategies. Such methods employ search algorithms over non-differentiable operations, which require a long time to obtain better strategies. On the contrary, we propose to make data augmentation operations differentiable to ease the search problem and enable much faster searching. To do so, we introduce gradient approximation for several non-differentiable operations. Data augmentation can be regarded as filling missing points from training data. To this end, we match the distributions of augmented data and the original data by adversarial learning. We show that our method is significantly faster than prior work without a performance drop.
								<br><br><B>Presented by </B>Mr. Ryuichiro Hataya</td>
							</tr>
						</table>
					</div>
		</div>
</section>
<hr>
<!-- Organization Section -->
    <section id="organization" class="bg-mid-gray">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 text-center">
					<h2 class="section-heading">Workshop Organizers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
			</div>
			<div class="col-sm-2">
				<div class="team-member">
					<!--<img alt="" class="img-responsive img-circle" src="Time%20Series%20Workshop_files/vitaly.jpg" />-->
					<a href="https://miaoxu-ml.github.io/">
					<h4>Miao Xu</h4>
					</a>
					<p class="text-muted"></p>
				</div>
			</div>
			<div class="col-sm-2">
				<div class="team-member">
					<!--<img alt="" class="img-responsive img-circle" src="Time%20Series%20Workshop_files/cheng.jpg" />-->
					<a href="https://sites.google.com/site/hrmarai1/">
					<h4>Hiromi Arai</h4>
					</a>
					<p class="text-muted"></p>
				</div>
			</div>
			<div class="col-sm-2">
				<div class="team-member">
					<!--<img alt="" class="img-responsive img-circle" src="Time%20Series%20Workshop_files/bernie.png" />-->
					<a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">
					<h4>Masashi Sugiyama</h4>
					</a>
					<p class="text-muted"></p>
				</div>
			</div>
</section>


</body></html>